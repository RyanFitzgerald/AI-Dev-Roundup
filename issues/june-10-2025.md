# üìö Apple‚Äôs Reasoning Limits, Codex Released, and Meta‚Äôs $15B AI Play

> June 10, 2025

## üß† AI News & Trends

### [Updates to Apple's On-Device and Server Foundation Language Models (5min read)](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Fmachinelearning.apple.com%2Fresearch%2Fapple-foundation-models-2025-updates&s=[[subscriberToken]])

At WWDC‚ÄØ2025, Apple introduced upgraded on-device (~3B param) and server-based
foundation language models powering Apple Intelligence, plus a new Foundation
Models framework granting third-party developers swift, privacy-preserving
access to on‚Äëdevice generative AI capabilities‚Äîeven offline‚Äîall using simple
Swift integration.

### [The Rise of ‚ÄòVibe Hacking‚Äô Is the Next AI Nightmare (6min read)](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Fwww.wired.com%2Fstory%2Fyoure-not-ready-for-ai-hacker-agents%2F&s=[[subscriberToken]])

Generative AI enables ‚Äúvibe hacking‚Äù: novices can now prompt LLMs to create
malware, while seasoned hackers can scale sophisticated, polymorphic
attacks‚Äîlike fast zero‚Äëday exploits. As AI‚Äëarmed adversaries rise, those
defending against it must leverage AI too.

### [Meta to pay nearly $15 billion for Scale AI stake, The Information reports (2min read)](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Fwww.reuters.com%2Fbusiness%2Fmeta-pay-nearly-15-billion-scale-ai-stake-information-reports-2025-06-10%2F&s=[[subscriberToken]])

Meta has agreed to buy a 49% stake in Scale‚ÄØAI for $14.8‚ÄØbillion, bringing Scale
CEO Alexandr Wang into Meta to lead a "superintelligence" lab aimed at boosting
its AI capabilities after Llama‚ÄØ4 underperformed. Scale, valued at
$13.8‚ÄØbillion, generated $870‚ÄØmillion in 2024 and projects over $2‚ÄØbillion
in 2025.

### [Anthropic‚Äôs AI-generated blog dies an early death (3min read)](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Ftechcrunch.com%2F2025%2F06%2F09%2Fanthropics-ai-generated-blog-dies-an-early-death%2F&s=[[subscriberToken]])

Anthropic quietly launched ‚ÄúClaude Explains,‚Äù an AI‚Äëgenerated, human‚Äëedited blog
aimed at showcasing its Claude model, but shut it down after a month amid
criticism over partial automation and concerns the pilot overstated Claude‚Äôs
accuracy and marketing intent.

## üõ†Ô∏è Dev Tools & Frameworks

### [Codex (5min read)](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Fopenai.com%2Findex%2Fintroducing-codex%2F&s=[[subscriberToken]])

OpenAI's cloud-based software engineering agent first introduced in May is now
available to ChatGPT Plus users. It can read, edit, test, and commit code in
isolated repos to write features, fix bugs, and propose PRs.

### [Model Context Protocol servers (GitHub)](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Fgithub.com%2Fmodelcontextprotocol%2Fservers&s=[[subscriberToken]])

This helpful repo contains a large collection of reference implementations for
MCP. It also contains references to community built servers and additional MCP
resources. Every reference implementation uses either the Typescript MCP SDK or
Python MCP SDK.

## ‚ö° Quick Bits

### [OpenAI releases o3-pro (1min read)](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Fhelp.openai.com%2Fen%2Farticles%2F9624314-model-release-notes%23h_77f7e366fe&s=[[subscriberToken]])

OpenAI released o3-pro for ChatGPT Pro users and for their API. It is a version
of o3 meant to think for longer periods of time and be more reliable in terms of
responses provided.

## üìå Deep Dive

### [AI Crash Course (GitHub)](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Fgithub.com%2Fhenrythe9th%2FAI-Crash-Course&s=[[subscriberToken]])

Built by Henry Shi, AI Crash Course is a GitHub repo with resources and a
learning plan for busy developers wanting to get up to speed with every
AI-related in 2 weeks.

### [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity (Research paper](https://e.aidevroundup.com/p/click?url=https%3A%2F%2Fmachinelearning.apple.com%2Fresearch%2Fillusion-of-thinking&s=[[subscriberToken]])

Apple researchers analyze when LLMs‚Äô chain-of-thought reasoning succeeds or
fails based on problem complexity, revealing that performance varies
significantly with task structure and highlighting both strengths and hidden
limitations.
